{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e5c7a9",
   "metadata": {},
   "source": [
    "### WEEK 2 HOMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33906488",
   "metadata": {},
   "source": [
    "**1**. Make sure you have installed BeautifulSoup and lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7175dc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/sophiasarica/opt/anaconda3/lib/python3.9/site-packages (4.12.2)\n",
      "Requirement already satisfied: lxml in /Users/sophiasarica/opt/anaconda3/lib/python3.9/site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/sophiasarica/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4) (2.2.1)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4 lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5cac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d239c9f",
   "metadata": {},
   "source": [
    "**2**. Use the website https://pythonprogramming.net/parsememcparseface/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707259b5",
   "metadata": {},
   "source": [
    "**3**. Connect to the website using urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a4b5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "978b5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to the website\n",
    "url = 'https://pythonprogramming.net/parsememcparseface/'\n",
    "request = urllib.request.urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3e0a8",
   "metadata": {},
   "source": [
    "**4**. Create an object called ‘soup’ using the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e188855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a 'soup' object using the source\n",
    "soup = BeautifulSoup(request, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96146bf",
   "metadata": {},
   "source": [
    "**5**. Print page title, get attributes, values, and beginning navigation. Get specific\n",
    "values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bed95889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Title: Python Programming Tutorials\n",
      "First paragraph tag's class: ['introduction']\n"
     ]
    }
   ],
   "source": [
    "#Print page title \n",
    "print(\"Page Title:\", soup.title.string)\n",
    "\n",
    "# Getting attributes, values, and specific values\n",
    "# print the first 'p' tag's class attribute\n",
    "first_p_tag = soup.find('p')\n",
    "print(\"First paragraph tag's class:\", first_p_tag['class'] if first_p_tag.has_attr('class') else \"No class attribute\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed60bb",
   "metadata": {},
   "source": [
    "**6**. Find all the paragraph instead of just one in the previous query  \n",
    "**7**. You can iterate through them using ‘str(paragraph.text)’  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "116d01c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, hello! This is a wonderful page meant to let you practice web scraping. This page was originally created to help people work with the Beautiful Soup 4 library.\n",
      "The following table gives some general information for the following programming languages:\n",
      "I think it's clear that, on a scale of 1-10, python is:\n",
      "Javascript (dynamic data) test:\n",
      "y u bad tho?\n",
      "Whᶐt hαppéns now¿\n",
      "sitemap\n",
      "Contact: Harrison@pythonprogramming.net.\n",
      "Programming is a superpower.\n"
     ]
    }
   ],
   "source": [
    "#Find all paragraphs and iterate through them\n",
    "for paragraph in soup.find_all('p'):\n",
    "    print(str(paragraph.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f0fb7",
   "metadata": {},
   "source": [
    "**8**. Grab all the links through ‘url.get(‘here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd7dddef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link URL: /\n",
      "Link URL: #\n",
      "Link URL: /\n",
      "Link URL: /+=1/\n",
      "Link URL: /support/\n",
      "Link URL: https://goo.gl/7zgAVQ\n",
      "Link URL: /login/\n",
      "Link URL: /register/\n",
      "Link URL: /\n",
      "Link URL: /+=1/\n",
      "Link URL: /support/\n",
      "Link URL: https://goo.gl/7zgAVQ\n",
      "Link URL: /login/\n",
      "Link URL: /register/\n",
      "Link URL: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
      "Link URL: /sitemap.xml\n",
      "Link URL: /support-donate/\n",
      "Link URL: /consulting/\n",
      "Link URL: https://www.facebook.com/pythonprogramming.net/\n",
      "Link URL: https://twitter.com/sentdex\n",
      "Link URL: https://instagram.com/sentdex\n",
      "Link URL: /about/tos/\n",
      "Link URL: /about/privacy-policy/\n",
      "Link URL: https://xkcd.com/353/\n"
     ]
    }
   ],
   "source": [
    "#Grab all the links\n",
    "links = soup.find_all('a')\n",
    "for link in links:\n",
    "    print(\"Link URL:\", link.get('href'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda48cc2",
   "metadata": {},
   "source": [
    "**9**. Just grab the text using ‘get_text’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4013cf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th link text: Consulting and Contracting\n"
     ]
    }
   ],
   "source": [
    "# Getting text from the 17th link \n",
    "if links:\n",
    "    print(\"17th link text:\", links[17].get_text())\n",
    "else:\n",
    "    print(\"No links found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd832990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0d326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1640d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
